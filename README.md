# Naive-Bayes-Classifier
Naive Bayes classifier is based on the Bayes’ Theorem, adapted for use across different machine learning problems. These include classification, clustering, and network analysis. This repository will explain how Naive Bayes is used for classification problems that sit under the supervised branch of the Machine Learning tree.
Talking about supervised learning, a quick reminder of the difference between regression and classification:
•	Regression aims to predict the value of a continuous target variable (e.g., price of a house)
•	Classification aims to predict the class label of a categorical target variable (e.g., spam email / not-spam email)
Why is Naive Bayes naive?
Naive Bayes' underlying assumption is that the predictors (attributes / independent variables) are independent of each other. This is a big assumption because it is easy to show that there is often at least some correlation between variables in real life. It is precisely this assumption of independence that makes Bayes classification “naive.”
Nevertheless, the Naive Bayes algorithm has been shown time and time again to perform really well in classification problems, despite the assumption of independence. Simultaneously, it is a fast algorithm since it scales easily to include many predictors without having to handle multi-dimensional correlations.
